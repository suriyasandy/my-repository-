# --- Imports ---
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from scipy.stats import genpareto
from arch.univariate import ConstantMean, GARCH
from sklearn.metrics import precision_score, recall_score
import math

# --- Settings ---
ROLL_WINDOW = 60
ANNUALIZE = np.sqrt(252)
EVT_THRESHOLD_PCT = 0.95
EVT_TAIL_PCT = 0.995
HYBRID_MULTIPLIER = 1.5
DEFAULT_PCT = 95

MANUAL_BANDS = [
    (0.00, 0.07, 0.07),
    (0.07, 0.50, 0.50),
    (0.50, 0.60, 0.60),
    (0.60, np.inf, 0.70),
]

# --- Streamlit Setup ---
st.set_page_config(layout="wide", page_title="FX Cross Threshold Dashboard")
st.title("FX Cross-Pair Threshold Dashboard â€“ Manual vs Hybrid")

# --- Upload File ---
fx_file = st.file_uploader("Upload FX CSV (Date, Currency, LogReturn, VolatilityOHLC)", type="csv")
if not fx_file:
    st.info("Please upload a valid FX dataset.")
    st.stop()

df = pd.read_csv(fx_file, parse_dates=["Date"])
for col in ["Date", "Currency", "LogReturn", "VolatilityOHLC"]:
    if col not in df.columns:
        st.error(f"Missing required column: {col}")
        st.stop()

# --- Preprocessing ---
df = df.sort_values("Date").reset_index(drop=True)
max_date = df["Date"].max()
cutoff = max_date - pd.Timedelta(days=7)
start = cutoff - pd.Timedelta(days=365)
df_cal = df[(df["Date"] > start) & (df["Date"] <= cutoff)].copy()

codes = sorted(df_cal["Currency"].unique())
cross_pairs = [a+b for i, a in enumerate(codes) for b in codes[i+1:]]

# --- Tabs Setup ---
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "Data Overview",
    "Manual Thresholds",
    "Hybrid Thresholds",
    "Cross-Pair Thresholds",
    "Performance Comparison",
    "Dynamic Threshold Recalibration",
    "Business Explanation"
])


def round_up_avg_vol(x):
    """Round up volatility value to next 0.1 multiple"""
    return (x * 100)

# --- Tab 1: Data Overview ---
with tab1:
    st.subheader("Overview: AvgNormVol and Manual Grouping")

    df_cal["NormVol"] = df_cal["VolatilityOHLC"] / np.sqrt(252)
    avg_vol = df_cal.groupby("Currency")["NormVol"].mean().reset_index(name="AvgNormVol")
    avg_vol['AvgNormVol'] = avg_vol['AvgNormVol'].apply(round_up_avg_vol)
    print(avg_vol)
    #avg_vol = avg_vol['AvgNormVol'].apply(round_up_avg_vol)

    st.dataframe(avg_vol, use_container_width=True)

    fig2 = px.bar(avg_vol, x="Currency", y="AvgNormVol", title="Average Normalized Volatility per Currency")
    st.plotly_chart(fig2, use_container_width=True)
# --- Helper Functions ---
def manual_threshold(norm_vol):
    for lo, hi, t in MANUAL_BANDS:
        if lo <= norm_vol < hi:
            return t
    return MANUAL_BANDS[-1][2]


def round_up_manual_threshold(x):
    """Round up volatility value to next 0.1 multiple"""
    return math.ceil(x * 10) / 10


def compute_dcc_cross_vol(ret1, ret2):
    # Clean returns
    rets = pd.concat([ret1, ret2], axis=1).dropna()
    if rets.shape[0] < ROLL_WINDOW:
        return np.nan
    
    # Rolling volatility
    vol1 = rets.iloc[:, 0].rolling(ROLL_WINDOW).std()
    vol2 = rets.iloc[:, 1].rolling(ROLL_WINDOW).std()
    
    # Rolling correlation
    corr = rets.iloc[:, 0].rolling(ROLL_WINDOW).corr(rets.iloc[:, 1])

    # Latest values
    sigma1 = vol1.iloc[-1]
    sigma2 = vol2.iloc[-1]
    rho = corr.iloc[-1]

    # DCC-like cross-volatility
    return np.sqrt(sigma1**2 + sigma2**2 + 2 * rho * sigma1 * sigma2)


def compute_evt_threshold(vol_series):
    u = vol_series.quantile(EVT_THRESHOLD_PCT)
    excess = vol_series[vol_series > u] - u
    if len(excess) < 10:
        return u * 1.2
    c, loc, scale = genpareto.fit(excess)
    return genpareto.ppf(EVT_TAIL_PCT, c, loc=loc, scale=scale) + u

# --- Tab 2: Manual Thresholds ---
with tab2:
    st.subheader("Manual Threshold Calculation")

    df_grouped = avg_vol.copy()
    df_grouped["ManualThreshold"] = df_grouped["AvgNormVol"].apply(manual_threshold).apply(round_up_manual_threshold)

    st.dataframe(df_grouped, use_container_width=True)

    fig3 = px.bar(df_grouped, x="Currency", y="ManualThreshold",
                 title="Manual Thresholds per Currency", color="ManualThreshold")
    st.plotly_chart(fig3, use_container_width=True)

    st.download_button("Download Manual Thresholds",
                       df_grouped.to_csv(index=False), "manual_thresholds.csv", "text/csv",key="manual_thresholds_download")

# --- Tab 3: Hybrid Thresholds ---
with tab3:
    st.subheader("Hybrid Threshold Calculation (DCC-GARCH + EVT)")

    sample_currency = st.selectbox("Select a Currency for Hybrid Threshold View", codes, key="hybridccy")
    df_sub = df_cal[df_cal["Currency"] == sample_currency]

    df_sub = df_sub.set_index("Date").sort_index()
    df_sub["RollVol"] = df_sub["LogReturn"].rolling(ROLL_WINDOW).std() * ANNUALIZE
    roll = df_sub["RollVol"].dropna()

    if len(roll) >= 60:
        sigma_dcc = compute_dcc_cross_vol(df_sub["LogReturn"], df_sub["LogReturn"])
        evt_thr = compute_evt_threshold(roll)
        hybrid_thr = max(HYBRID_MULTIPLIER * sigma_dcc, evt_thr)

        fig4 = px.line(x=roll.index, y=roll.values, labels={'x': 'Date', 'y': 'Annualized Vol'},
                      title=f"Rolling Volatility for {sample_currency}")
        fig4.add_hline(y=hybrid_thr, line_dash="solid", line_color="green", annotation_text="Hybrid Threshold")
        st.plotly_chart(fig4, use_container_width=True)

        st.markdown(f"**Hybrid Threshold:** {hybrid_thr:.4f}")

    else:
        st.warning("Not enough data to compute rolling volatility!")
# --- Tab 4: Cross-Pair Thresholds ---
with tab4:
    st.subheader("Cross-Pair Thresholds (Manual vs Hybrid)")

    pair = st.selectbox("Select a Cross Pair", cross_pairs)
    base, quote = pair[:3], pair[3:]

    piv = df_cal.pivot(index="Date", columns="Currency", values="LogReturn")

    if base in piv.columns and quote in piv.columns:
        ret_base = piv[base].dropna()
        ret_quote = piv[quote].dropna()
        cross_ret = ret_base - ret_quote

        cross_vol = cross_ret.rolling(ROLL_WINDOW).std() * ANNUALIZE
        cross_vol = cross_vol.dropna()

        # Manual thresholds
        base_thresh = df_grouped.loc[df_grouped["Currency"] == base, "ManualThreshold"].values[0]
        quote_thresh = df_grouped.loc[df_grouped["Currency"] == quote, "ManualThreshold"].values[0]
        manual_cross_thresh = max(base_thresh, quote_thresh)

        # Hybrid thresholds
        if len(cross_ret) >= 60:
            sigma_dcc = compute_dcc_cross_vol(ret_base, ret_quote)
            evt_thr = compute_evt_threshold(cross_vol)
            hybrid_cross_thresh = max(HYBRID_MULTIPLIER * sigma_dcc, evt_thr)

            fig5 = px.line(x=cross_vol.index, y=cross_vol.values,
                          labels={'x': 'Date', 'y': 'Annualized Vol'},
                          title=f"Cross-Pair Volatility: {pair}")
            fig5.add_hline(y=manual_cross_thresh, line_dash="dash", line_color="gray", annotation_text="Manual Threshold")
            fig5.add_hline(y=hybrid_cross_thresh, line_dash="solid", line_color="green", annotation_text="Hybrid Threshold")
            st.plotly_chart(fig5, use_container_width=True)

            st.markdown(f"- **Manual Threshold:** {manual_cross_thresh:.4f}")
            st.markdown(f"- **Hybrid Threshold:** {hybrid_cross_thresh:.4f}")
        else:
            st.warning("Not enough data to compute hybrid thresholds for this pair.")
    else:
        st.warning("Selected currencies not available!")

# --- Tab 5: Performance Comparison ---
with tab5:
    st.subheader("Performance Comparison (Manual vs Hybrid)")

    if base in piv.columns and quote in piv.columns:
        ret_base = piv[base].dropna()
        ret_quote = piv[quote].dropna()
        cross_ret = ret_base - ret_quote

        cross_vol = cross_ret.rolling(ROLL_WINDOW).std() * ANNUALIZE
        cross_vol = cross_vol.dropna()

        if len(cross_ret) >= 60:
            true_event = cross_vol > cross_vol.quantile(0.99)

            manual_flag = cross_vol > manual_cross_thresh
            hybrid_flag = cross_vol > hybrid_cross_thresh

            perf_df = pd.DataFrame({
                "Method": ["Manual", "Hybrid"],
                "Precision": [precision_score(true_event, manual_flag), precision_score(true_event, hybrid_flag)],
                "Recall": [recall_score(true_event, manual_flag), recall_score(true_event, hybrid_flag)]
            })

            st.dataframe(perf_df.style.format({"Precision": "{:.1%}", "Recall": "{:.1%}"}), use_container_width=True)

            st.download_button("Download Performance Table",
                               perf_df.to_csv(index=False), "performance_comparison.csv", "text/csv",key="performance_compariso_download")
# --- Tab 4: Cross-Pair Thresholds ---
with tab4:
    st.subheader("Cross-Pair Thresholds (Manual vs Hybrid)")

    pr = st.selectbox("Select a Cross Pair To Check", cross_pairs)
    base, quote = pr[:3], pr[3:]

    piv = df_cal.pivot(index="Date", columns="Currency", values="LogReturn")

    if base in piv.columns and quote in piv.columns:
        ret_base = piv[base].dropna()
        ret_quote = piv[quote].dropna()
        cross_ret = ret_base - ret_quote

        cross_vol = cross_ret.rolling(ROLL_WINDOW).std() * ANNUALIZE
        cross_vol = cross_vol.dropna()

        # Manual thresholds
        base_thresh = df_grouped.loc[df_grouped["Currency"] == base, "ManualThreshold"].values[0]
        quote_thresh = df_grouped.loc[df_grouped["Currency"] == quote, "ManualThreshold"].values[0]
        manual_cross_thresh = max(base_thresh, quote_thresh)

        # Hybrid thresholds
        if len(cross_ret) >= 60:
            sigma_dcc = compute_dcc_cross_vol(ret_base, ret_quote)
            evt_thr = compute_evt_threshold(cross_vol)
            hybrid_cross_thresh = max(HYBRID_MULTIPLIER * sigma_dcc, evt_thr)

            fig6 = px.line(x=cross_vol.index, y=cross_vol.values,
                          labels={'x': 'Date', 'y': 'Annualized Vol'},
                          title=f"Cross-Pair Volatility: {pr}")
            fig6.add_hline(y=manual_cross_thresh, line_dash="dash", line_color="gray", annotation_text="Manual Threshold")
            fig6.add_hline(y=hybrid_cross_thresh, line_dash="solid", line_color="green", annotation_text="Hybrid Threshold")
            st.plotly_chart(fig6, use_container_width=True,key="Unique")

            st.markdown(f"- **Manual Threshold:** {manual_cross_thresh:.4f}")
            st.markdown(f"- **Hybrid Threshold:** {hybrid_cross_thresh:.4f}")
        else:
            st.warning("Not enough data to compute hybrid thresholds for this pair.")
    else:
        st.warning("Selected currencies not available!")

# --- Tab 5: Performance Comparison ---
with tab5:
    st.subheader("Performance Comparison (Manual vs Hybrid)")

    if base in piv.columns and quote in piv.columns:
        ret_base = piv[base].dropna()
        ret_quote = piv[quote].dropna()
        cross_ret = ret_base - ret_quote

        cross_vol = cross_ret.rolling(ROLL_WINDOW).std() * ANNUALIZE
        cross_vol = cross_vol.dropna()

        if len(cross_ret) >= 60:
            true_event = cross_vol > cross_vol.quantile(0.99)

            manual_flag = cross_vol > manual_cross_thresh
            hybrid_flag = cross_vol > hybrid_cross_thresh

            perf_df = pd.DataFrame({
                "Method": ["Manual", "Hybrid"],
                "Precision": [precision_score(true_event, manual_flag), precision_score(true_event, hybrid_flag)],
                "Recall": [recall_score(true_event, manual_flag), recall_score(true_event, hybrid_flag)]
            })

            st.dataframe(perf_df.style.format({"Precision": "{:.1%}", "Recall": "{:.1%}"}), use_container_width=True)

            st.download_button("Download Performance Table",
                               perf_df.to_csv(index=False), "performance_comparison.csv", "text/csv",key="performance_comparison_Download")

# --- Tab 6: Dynamic Threshold Recalibration ---
with tab6:
    st.subheader("7. Dynamic Threshold Recalibration (Jan 2024 Events)")

    st.markdown("""
    - Compare manual fixed thresholds (calibrated on 2023 data)  
    - vs. dynamically recalculated hybrid thresholds (after Jan 2024 volatility events).
    """)

    # Filter last 1 year (Feb 2023 to Jan 2024)
    recal_start = pd.to_datetime("2023-02-01")
    recal_end = pd.to_datetime("2024-01-31")
    df_recal = df[(df["Date"] >= recal_start) & (df["Date"] <= recal_end)]

    # Rolling Volatility
    roll_recal = (
        df_recal.set_index("Date")
               .groupby("Currency")["LogReturn"]
               .rolling(ROLL_WINDOW, min_periods=ROLL_WINDOW)
               .std()
               .reset_index()
    )
    roll_recal.rename(columns={"LogReturn": "RollVol"}, inplace=True)
    roll_recal["RollVol"] *= ANNUALIZE

    # Dynamic Thresholds
    stat_recal = (roll_recal.groupby("Currency")["RollVol"]
                           .quantile(DEFAULT_PCT/100)
                           .reset_index(name="DynamicThreshold"))

    # Latest Rolling Vol per Currency
    latest_recal = (roll_recal.groupby("Currency")
                              .apply(lambda x: x.sort_values("Date")["RollVol"].iloc[-1])
                              .reset_index(name="LatestVol"))

    # Merge manual thresholds (from tab2 avg_ohlc) and dynamic thresholds
    recal_summary = avg_vol.copy()
    recal_summary["ManualThreshold"] = recal_summary["AvgNormVol"].apply(manual_threshold).apply(round_up_manual_threshold)

    recal_summary = recal_summary.merge(stat_recal, on="Currency", how="inner")\
                                 .merge(latest_recal, on="Currency", how="inner")

    recal_summary["Flag_Manual"] = recal_summary["LatestVol"] > recal_summary["ManualThreshold"]
    recal_summary["Flag_Dynamic"] = recal_summary["LatestVol"] > recal_summary["DynamicThreshold"]

    st.dataframe(recal_summary.round(4), use_container_width=True)

    # Download Option
    st.download_button("Download Dynamic Recalibration Table",
                       recal_summary.to_csv(index=False),
                       "dynamic_recalibration_thresholds.csv",
                       "text/csv",
                       key="recalibration_download")

    # Visualization
    ccy_select = st.selectbox("Visualize Currency Recalibration", recal_summary["Currency"].unique(), key="recalibrationccy")

    d_plot = roll_recal[roll_recal["Currency"] == ccy_select].set_index("Date")
    fig7 = px.line(d_plot, y="RollVol", title=f"{ccy_select} Rolling Vol with Thresholds")
    man_thresh = recal_summary.loc[recal_summary["Currency"] == ccy_select, "ManualThreshold"].values[0]
    dyn_thresh = recal_summary.loc[recal_summary["Currency"] == ccy_select, "DynamicThreshold"].values[0]
    fig7.add_hline(y=man_thresh, line_dash="dash", line_color="gray", annotation_text="Manual Threshold")
    fig7.add_hline(y=dyn_thresh, line_dash="solid", line_color="green", annotation_text="Dynamic Threshold")
    st.plotly_chart(fig7, use_container_width=True)


# --- Tab 7: Business Explanation ---
with tab7:
    st.subheader("Business Justification: Manual vs Hybrid Approach")

    st.markdown("""
    ## Manual Approach
    - **Static**: Thresholds set annually based on past one year average normalized volatility.
    - **Grouping**: Currencies grouped manually into 4 bands based on arbitrary ranges.
    - **Threshold assignment**: Fixed per group, often rounded manually.
    - **Drawbacks**:
        - Cannot adapt to sudden market changes (e.g., war, election volatility).
        - No forward-looking volatility prediction.
        - Risk of stale thresholds leading to either false positives or missed true events.

    ## Hybrid Approach (Our Proposal)
    - **Dynamic**: Recalibrated every month using the most recent one year of data.
    - **DCC-GARCH Forecast**: Captures forward-looking volatility clustering.
    - **Extreme Value Theory (EVT)**: Statistically estimates threshold at 99.5% tail risk.
    - **Threshold Setting**: 
        - Higher of DCC forecast Ã— multiplier vs EVT tail quantile.
    - **Benefits**:
        - Responds to evolving market conditions.
        - Balanced between avoiding false positives and catching true alerts.
        - Fully explainable mathematically and auditable.
    
    ## Conclusion
    > Hybrid thresholding provides a more robust, dynamic, and statistically defensible way to detect genuine off-market trades, ensuring operational stability and reducing manual interventions.

    """)

    st.success("Proposed Hybrid Approach is Dynamic, Data-Driven, and Statistically Defensible.")

# --- End of Streamlit App ---
